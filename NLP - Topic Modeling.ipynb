{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Set 4\n",
    "## Machine Learning  \n",
    "## PPHA 30545  \n",
    "## Yinjiang Xiong  \n",
    "## Due: March 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import scipy.sparse\n",
    "from gensim import matutils, models\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Load the data as a corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(os.path.join(os.getcwd(), 'SimpleText_auto', '*.txt'))\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for file_path in file_list:\n",
    "    with open(file_path) as f_input:\n",
    "        corpus.append(f_input.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(corpus)\n",
    "dtm = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00003</th>\n",
       "      <th>00004</th>\n",
       "      <th>0001</th>\n",
       "      <th>0001g</th>\n",
       "      <th>00025t</th>\n",
       "      <th>00037</th>\n",
       "      <th>0005g</th>\n",
       "      <th>...</th>\n",
       "      <th>ℓn2qeyℓ</th>\n",
       "      <th>ℓw</th>\n",
       "      <th>ℓϵ</th>\n",
       "      <th>ⅆi1ⅆt</th>\n",
       "      <th>ⅆi2ⅆt</th>\n",
       "      <th>ⅆi3ⅆt</th>\n",
       "      <th>ⅆjˆⅆmδm</th>\n",
       "      <th>ⅆjⅆm</th>\n",
       "      <th>ⅆudcⅆt</th>\n",
       "      <th>ⅇ1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30718 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  00003  00004  0001  0001g  00025t  00037  0005g  ...  \\\n",
       "0   0    3     0      0      0     0      0       0      0      0  ...   \n",
       "1   0    0     0      0      0     0      0       0      0      0  ...   \n",
       "2   2    0     0      0      0     0      0       0      0      0  ...   \n",
       "3   0    0     0      0      0     0      0       0      0      0  ...   \n",
       "4   0    0     0      0      0     0      0       0      0      0  ...   \n",
       "\n",
       "   ℓn2qeyℓ  ℓw  ℓϵ  ⅆi1ⅆt  ⅆi2ⅆt  ⅆi3ⅆt  ⅆjˆⅆmδm  ⅆjⅆm  ⅆudcⅆt  ⅇ1  \n",
       "0        0   0   0      0      0      0        0     0       0   0  \n",
       "1        1  17   3      0      0      0        0     0       0   0  \n",
       "2        0   0   0      0      0      0        0     0       0   0  \n",
       "3        0   0   0      0      0      0        0     0       0   0  \n",
       "4        0   0   0      0      0      0        0     0       0   0  \n",
       "\n",
       "[5 rows x 30718 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# document-term matrix\n",
    "dtm.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Clean the data. This implies transforming all characters to lowercase and removing stop words, punctuation, and any other words that will not generate meaningful content for identifying the topics. Think about words that are likely common in academic papers (e.g., table, figure, results). Also think about combining forms of the same word (e.g., genes and gene). Be sure to justify your decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, convert all words to lowercase, strip accents and remove the top 20% most frequent and keep words with at least 10 appearances\n",
    "# setting max and min helps get rid of the meaningless words that appear a lot and obscure words that appear less than 10 times\n",
    "# this significantly reduced features from 30718 to 2966\n",
    "vec_1 = CountVectorizer(lowercase=True, strip_accents='unicode', max_df=0.8, min_df=10)\n",
    "X_1 = vec_1.fit_transform(corpus)\n",
    "dtm_1 = pd.DataFrame(X_1.toarray(), columns=vec_1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>001</th>\n",
       "      <th>005</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>...</th>\n",
       "      <th>yielding</th>\n",
       "      <th>yields</th>\n",
       "      <th>young</th>\n",
       "      <th>zeiss</th>\n",
       "      <th>zero</th>\n",
       "      <th>zhang</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>δt</th>\n",
       "      <th>μm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2966 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  001  005  01  02  03  04  05  06  07  ...  yielding  yields  young  \\\n",
       "0    3    0    0   1   0   0   0   0   0   0  ...         0      16      0   \n",
       "1    0    0    0   1   0   0   0   0   0   0  ...         0       6      0   \n",
       "2    0    0    0   0   1   0   0   1   0   0  ...         0       0      2   \n",
       "3    0    0    0   0   0   0   0   0   0   0  ...         0       0      0   \n",
       "4    0    0    0   4   0   0   3   4   2   1  ...         1       3      0   \n",
       "\n",
       "   zeiss  zero  zhang  zone  zones  δt  μm  \n",
       "0      0     0      0     1      8   0   0  \n",
       "1      0     8      0     0      0   0   0  \n",
       "2      0     0      0     6     10   0   0  \n",
       "3      0     0      0     0      0   0   0  \n",
       "4      0     3      0     0      0   0   0  \n",
       "\n",
       "[5 rows x 2966 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27697"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vec_1.stop_words_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete academic words\n",
    "academic = ['table', 'tables', 'figure', 'figures', 'result', 'results', 'hypothesis', 'hypotheses', 'research', 'yield', 'et']\n",
    "for feature in dtm_1:\n",
    "    if feature in academic:\n",
    "        dtm_1.drop(feature, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete words that contain non-letter\n",
    "for feature in dtm_1:\n",
    "    if not feature.isalpha():\n",
    "        dtm_1.drop(feature, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>absence</th>\n",
       "      <th>absent</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absorbed</th>\n",
       "      <th>absorption</th>\n",
       "      <th>...</th>\n",
       "      <th>yielding</th>\n",
       "      <th>yields</th>\n",
       "      <th>young</th>\n",
       "      <th>zeiss</th>\n",
       "      <th>zero</th>\n",
       "      <th>zhang</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>δt</th>\n",
       "      <th>μm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2758 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability  able  abnormal  about  above  absence  absent  absolute  absorbed  \\\n",
       "0        0     0         0      4      3        0       0         0         0   \n",
       "1        0     0         0      0      4        0       0         0         0   \n",
       "2        0     0         0      1      1        1       1         0         0   \n",
       "3        2     0         0      1      3        0       0         0         0   \n",
       "4        0     3         0      1      6        0       0        10         0   \n",
       "\n",
       "   absorption  ...  yielding  yields  young  zeiss  zero  zhang  zone  zones  \\\n",
       "0           0  ...         0      16      0      0     0      0     1      8   \n",
       "1           0  ...         0       6      0      0     8      0     0      0   \n",
       "2           0  ...         0       0      2      0     0      0     6     10   \n",
       "3           7  ...         0       0      0      0     0      0     0      0   \n",
       "4           0  ...         1       3      0      0     3      0     0      0   \n",
       "\n",
       "   δt  μm  \n",
       "0   0   0  \n",
       "1   0   0  \n",
       "2   0   0  \n",
       "3   0   0  \n",
       "4   0   0  \n",
       "\n",
       "[5 rows x 2758 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, combine words in singular and plural forms\n",
    "for feature in dtm_1:\n",
    "    if feature+'s' in dtm_1:\n",
    "        dtm_1[feature] = dtm_1[feature] + dtm_1[feature+'s']\n",
    "        dtm_1.drop([feature+'s'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>absence</th>\n",
       "      <th>absent</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absorbed</th>\n",
       "      <th>absorption</th>\n",
       "      <th>...</th>\n",
       "      <th>yet</th>\n",
       "      <th>yielding</th>\n",
       "      <th>yields</th>\n",
       "      <th>young</th>\n",
       "      <th>zeiss</th>\n",
       "      <th>zero</th>\n",
       "      <th>zhang</th>\n",
       "      <th>zone</th>\n",
       "      <th>δt</th>\n",
       "      <th>μm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability  able  abnormal  about  above  absence  absent  absolute  absorbed  \\\n",
       "0        0     0         0      4      3        0       0         0         0   \n",
       "1        0     0         0      0      4        0       0         0         0   \n",
       "2        0     0         0      1      1        1       1         0         0   \n",
       "3        2     0         0      1      3        0       0         0         0   \n",
       "4        0     3         0      1      6        0       0        10         0   \n",
       "\n",
       "   absorption  ...  yet  yielding  yields  young  zeiss  zero  zhang  zone  \\\n",
       "0           0  ...    0         0      16      0      0     0      0     9   \n",
       "1           0  ...    0         0       6      0      0     8      0     0   \n",
       "2           0  ...    0         0       0      2      0     0      0    16   \n",
       "3           7  ...    0         0       0      0      0     0      0     0   \n",
       "4           0  ...    2         1       3      0      0     3      0     0   \n",
       "\n",
       "   δt  μm  \n",
       "0   0   0  \n",
       "1   0   0  \n",
       "2   0   0  \n",
       "3   0   0  \n",
       "4   0   0  \n",
       "\n",
       "[5 rows x 2411 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Present the 50 most frequently used words in the corpus in an informative way. This can include a table of results or a word cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('model', 1864),\n",
       " ('time', 1424),\n",
       " ('cell', 1375),\n",
       " ('value', 1303),\n",
       " ('flow', 1185),\n",
       " ('system', 1130),\n",
       " ('case', 1117),\n",
       " ('set', 1081),\n",
       " ('level', 1060),\n",
       " ('soil', 981),\n",
       " ('section', 941),\n",
       " ('state', 922),\n",
       " ('energy', 917),\n",
       " ('temperature', 909),\n",
       " ('surface', 852),\n",
       " ('region', 843),\n",
       " ('field', 841),\n",
       " ('electron', 829),\n",
       " ('change', 804),\n",
       " ('condition', 798),\n",
       " ('rate', 749),\n",
       " ('will', 733),\n",
       " ('increase', 727),\n",
       " ('line', 720),\n",
       " ('node', 708),\n",
       " ('sample', 702),\n",
       " ('particle', 695),\n",
       " ('observed', 692),\n",
       " ('low', 689),\n",
       " ('effect', 680),\n",
       " ('ratio', 677),\n",
       " ('algorithm', 675),\n",
       " ('function', 669),\n",
       " ('use', 644),\n",
       " ('size', 642),\n",
       " ('wind', 641),\n",
       " ('difference', 632),\n",
       " ('since', 630),\n",
       " ('group', 618),\n",
       " ('network', 610),\n",
       " ('site', 610),\n",
       " ('method', 609),\n",
       " ('mean', 607),\n",
       " ('factor', 585),\n",
       " ('see', 582),\n",
       " ('let', 571),\n",
       " ('gene', 569),\n",
       " ('ion', 560),\n",
       " ('depth', 556),\n",
       " ('given', 551)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = []\n",
    "for feature in dtm_1:\n",
    "    freq.append((feature, dtm_1[feature].sum()))\n",
    "freq_sort_50 = [(k, v) for k, v in sorted(freq, key=lambda item: item[1], reverse=True)][:50]\n",
    "freq_sort_50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Fit a topic model on the corpus setting k equal to 2, 3, 5, 8, and 10. Present the topics for each value of k and interpret the topics. In your opinion, which of the selected values of k yield the most meaningful coherence for each topic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ability</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>able</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>abnormal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>about</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>above</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3    4    5    6    7    8    9    ...  100  101  \\\n",
       "ability     0    0    0    2    0    0    2    0    0    0  ...    0    1   \n",
       "able        0    0    0    0    3    0    0    1    3    0  ...    1    3   \n",
       "abnormal    0    0    0    0    0    0    0    0    0    0  ...    0    1   \n",
       "about       4    0    1    1    1    0   10   11    0    0  ...    0   10   \n",
       "above       3    4    1    3    6    4    4   37    1    0  ...    1   10   \n",
       "\n",
       "          102  103  104  105  106  107  108  109  \n",
       "ability     1    1    0    0    0   15    2    0  \n",
       "able        1    0    0    0    0    4    6    0  \n",
       "abnormal    0    0    0    0    0    1    0    0  \n",
       "about       2    5    1    5    1    4   25    0  \n",
       "above       1    1   13    2    8    4   31    0  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm = dtm_1.transpose()\n",
    "tdm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus_gen = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {}\n",
    "id = 0\n",
    "for word in dtm_1:\n",
    "    id2word[id] = word\n",
    "    id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.011*\"model\" + 0.008*\"flow\" + 0.007*\"case\" + 0.007*\"set\" + 0.006*\"energy\" + 0.006*\"time\" + 0.006*\"value\" + 0.006*\"electron\" + 0.005*\"particle\" + 0.005*\"field\"'),\n",
       " (1,\n",
       "  '0.011*\"cell\" + 0.008*\"soil\" + 0.006*\"state\" + 0.006*\"level\" + 0.005*\"node\" + 0.005*\"sample\" + 0.005*\"time\" + 0.005*\"system\" + 0.005*\"gene\" + 0.004*\"value\"')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k = 2\n",
    "lda = models.LdaModel(corpus=corpus_gen, id2word=id2word, num_topics=2, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "topic 1: chemistry  \n",
    "topic 2: biology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.011*\"wind\" + 0.011*\"particle\" + 0.010*\"let\" + 0.009*\"case\" + 0.009*\"set\" + 0.008*\"element\" + 0.008*\"group\" + 0.007*\"power\" + 0.006*\"model\" + 0.006*\"theorem\"'),\n",
       " (1,\n",
       "  '0.010*\"time\" + 0.010*\"state\" + 0.010*\"node\" + 0.010*\"model\" + 0.010*\"algorithm\" + 0.008*\"flow\" + 0.007*\"set\" + 0.007*\"system\" + 0.006*\"value\" + 0.006*\"module\"'),\n",
       " (2,\n",
       "  '0.009*\"cell\" + 0.007*\"soil\" + 0.006*\"model\" + 0.006*\"temperature\" + 0.006*\"electron\" + 0.005*\"energy\" + 0.005*\"surface\" + 0.005*\"level\" + 0.004*\"value\" + 0.004*\"sample\"')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k = 3\n",
    "lda = models.LdaModel(corpus=corpus_gen, id2word=id2word, num_topics=3, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "topic 1: physics theory  \n",
    "topic 2: test  \n",
    "topic 3: environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.011*\"surface\" + 0.010*\"particle\" + 0.008*\"layer\" + 0.008*\"flow\" + 0.008*\"feature\" + 0.008*\"value\" + 0.007*\"model\" + 0.007*\"image\" + 0.006*\"measurement\" + 0.006*\"sample\"'),\n",
       " (1,\n",
       "  '0.013*\"state\" + 0.013*\"node\" + 0.012*\"algorithm\" + 0.011*\"time\" + 0.010*\"model\" + 0.007*\"system\" + 0.007*\"module\" + 0.007*\"network\" + 0.007*\"power\" + 0.006*\"memory\"'),\n",
       " (2,\n",
       "  '0.019*\"set\" + 0.015*\"let\" + 0.010*\"function\" + 0.009*\"case\" + 0.009*\"theorem\" + 0.009*\"clusters\" + 0.008*\"lemma\" + 0.008*\"element\" + 0.007*\"since\" + 0.007*\"section\"'),\n",
       " (3,\n",
       "  '0.012*\"model\" + 0.008*\"temperature\" + 0.007*\"value\" + 0.007*\"flow\" + 0.007*\"change\" + 0.006*\"rate\" + 0.005*\"region\" + 0.005*\"energy\" + 0.005*\"site\" + 0.005*\"ratio\"'),\n",
       " (4,\n",
       "  '0.019*\"cell\" + 0.011*\"soil\" + 0.011*\"electron\" + 0.008*\"gene\" + 0.006*\"plant\" + 0.006*\"energy\" + 0.005*\"expression\" + 0.005*\"level\" + 0.005*\"ion\" + 0.005*\"field\"')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k = 5\n",
    "lda = models.LdaModel(corpus=corpus_gen, id2word=id2word, num_topics=5, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "topic 1: experiment  \n",
    "topic 2: theory  \n",
    "topic 3: ?  \n",
    "topic 4: variables  \n",
    "topic 5: environmental science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.020*\"soil\" + 0.010*\"plant\" + 0.009*\"patient\" + 0.007*\"species\" + 0.007*\"level\" + 0.007*\"root\" + 0.007*\"protein\" + 0.006*\"gene\" + 0.006*\"sample\" + 0.006*\"activity\"'),\n",
       " (1,\n",
       "  '0.030*\"cell\" + 0.012*\"algorithm\" + 0.009*\"gene\" + 0.009*\"expression\" + 0.008*\"clusters\" + 0.007*\"system\" + 0.007*\"model\" + 0.006*\"size\" + 0.006*\"memory\" + 0.006*\"line\"'),\n",
       " (2,\n",
       "  '0.013*\"sediment\" + 0.009*\"ratio\" + 0.009*\"device\" + 0.008*\"distribution\" + 0.008*\"ti\" + 0.007*\"energy\" + 0.006*\"selection\" + 0.006*\"heavy\" + 0.006*\"risk\" + 0.006*\"core\"'),\n",
       " (3,\n",
       "  '0.015*\"set\" + 0.012*\"let\" + 0.011*\"flow\" + 0.010*\"feature\" + 0.010*\"function\" + 0.008*\"case\" + 0.008*\"group\" + 0.008*\"image\" + 0.008*\"theorem\" + 0.007*\"section\"'),\n",
       " (4,\n",
       "  '0.017*\"electron\" + 0.013*\"energy\" + 0.010*\"wind\" + 0.010*\"ion\" + 0.009*\"region\" + 0.007*\"field\" + 0.007*\"power\" + 0.007*\"case\" + 0.006*\"speed\" + 0.006*\"channel\"'),\n",
       " (5,\n",
       "  '0.027*\"node\" + 0.019*\"state\" + 0.014*\"module\" + 0.014*\"time\" + 0.010*\"network\" + 0.010*\"element\" + 0.009*\"ideal\" + 0.009*\"left\" + 0.008*\"set\" + 0.008*\"maximal\"'),\n",
       " (6,\n",
       "  '0.012*\"particle\" + 0.009*\"sample\" + 0.009*\"surface\" + 0.008*\"value\" + 0.008*\"site\" + 0.007*\"material\" + 0.007*\"layer\" + 0.007*\"temperature\" + 0.007*\"soil\" + 0.006*\"system\"'),\n",
       " (7,\n",
       "  '0.021*\"model\" + 0.013*\"flow\" + 0.012*\"temperature\" + 0.008*\"depth\" + 0.008*\"surface\" + 0.008*\"velocity\" + 0.007*\"atmosphere\" + 0.007*\"time\" + 0.007*\"profile\" + 0.007*\"rate\"')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k = 8\n",
    "lda = models.LdaModel(corpus=corpus_gen, id2word=id2word, num_topics=8, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "topic 1: environmental science\n",
    "topic 2: genetic biology  \n",
    "topic 3: ?  \n",
    "topic 4: academic noun  \n",
    "topic 5: renewable energy  \n",
    "topic 6: ?  \n",
    "topic 7: site  \n",
    "topic 8: controlled variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.026*\"model\" + 0.019*\"temperature\" + 0.013*\"atmosphere\" + 0.010*\"heating\" + 0.010*\"line\" + 0.009*\"region\" + 0.009*\"energy\" + 0.009*\"rate\" + 0.009*\"observation\" + 0.009*\"solar\"'),\n",
       " (1,\n",
       "  '0.022*\"algorithm\" + 0.019*\"model\" + 0.018*\"memory\" + 0.016*\"core\" + 0.012*\"performance\" + 0.012*\"element\" + 0.010*\"resource\" + 0.010*\"concentration\" + 0.009*\"machine\" + 0.009*\"trace\"'),\n",
       " (2,\n",
       "  '0.035*\"cell\" + 0.014*\"gene\" + 0.010*\"expression\" + 0.009*\"patient\" + 0.008*\"culture\" + 0.008*\"human\" + 0.006*\"level\" + 0.006*\"line\" + 0.005*\"protein\" + 0.005*\"day\"'),\n",
       " (3,\n",
       "  '0.019*\"state\" + 0.019*\"node\" + 0.013*\"time\" + 0.012*\"set\" + 0.011*\"algorithm\" + 0.010*\"system\" + 0.009*\"module\" + 0.008*\"network\" + 0.007*\"will\" + 0.006*\"value\"'),\n",
       " (4,\n",
       "  '0.032*\"soil\" + 0.014*\"plant\" + 0.011*\"species\" + 0.008*\"root\" + 0.007*\"site\" + 0.007*\"change\" + 0.007*\"effect\" + 0.006*\"organic\" + 0.006*\"treatment\" + 0.006*\"water\"'),\n",
       " (5,\n",
       "  '0.035*\"electron\" + 0.021*\"energy\" + 0.017*\"ion\" + 0.014*\"field\" + 0.013*\"wave\" + 0.010*\"signature\" + 0.010*\"distribution\" + 0.009*\"magnetic\" + 0.008*\"wake\" + 0.008*\"region\"'),\n",
       " (6,\n",
       "  '0.024*\"flow\" + 0.015*\"wind\" + 0.014*\"model\" + 0.010*\"velocity\" + 0.008*\"speed\" + 0.008*\"power\" + 0.008*\"time\" + 0.007*\"vertical\" + 0.007*\"value\" + 0.006*\"case\"'),\n",
       " (7,\n",
       "  '0.024*\"let\" + 0.019*\"set\" + 0.015*\"theorem\" + 0.013*\"lemma\" + 0.013*\"element\" + 0.013*\"function\" + 0.012*\"case\" + 0.012*\"group\" + 0.011*\"proof\" + 0.011*\"ideal\"'),\n",
       " (8,\n",
       "  '0.009*\"sediment\" + 0.009*\"clusters\" + 0.007*\"site\" + 0.006*\"ratio\" + 0.006*\"coherent\" + 0.006*\"system\" + 0.006*\"material\" + 0.006*\"value\" + 0.005*\"sample\" + 0.005*\"change\"'),\n",
       " (9,\n",
       "  '0.030*\"particle\" + 0.015*\"surface\" + 0.012*\"value\" + 0.012*\"layer\" + 0.011*\"temperature\" + 0.010*\"film\" + 0.009*\"material\" + 0.007*\"sample\" + 0.007*\"growth\" + 0.007*\"size\"')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k = 10\n",
    "lda = models.LdaModel(corpus=corpus_gen, id2word=id2word, num_topics=10, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "topic 1: solar  \n",
    "topic 2: model  \n",
    "topic 3: biology    \n",
    "topic 4: network  \n",
    "topic 5: environmental science  \n",
    "topic 6: chemistry  \n",
    "topic 7: physics  \n",
    "topic 8: theory  \n",
    "topic 9: material science  \n",
    "topic 10: material science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, 10 topics give a somewhat clear description for each topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Optimize the hyperparameters of the LDA model using 10-fold cross-validation. Present the topics from the best model and explain your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.009*\"feature\" + 0.008*\"model\" + 0.008*\"flow\" + 0.007*\"layer\" + 0.007*\"depth\" + 0.006*\"site\" + 0.006*\"device\" + 0.006*\"section\" + 0.006*\"change\" + 0.006*\"time\"'),\n",
       " (1,\n",
       "  '0.009*\"surface\" + 0.009*\"image\" + 0.008*\"film\" + 0.007*\"group\" + 0.007*\"observed\" + 0.007*\"material\" + 0.007*\"solution\" + 0.006*\"peak\" + 0.006*\"value\" + 0.006*\"feature\"'),\n",
       " (2,\n",
       "  '0.032*\"particle\" + 0.013*\"value\" + 0.013*\"temperature\" + 0.012*\"concentration\" + 0.011*\"sample\" + 0.010*\"element\" + 0.008*\"layer\" + 0.008*\"material\" + 0.007*\"surface\" + 0.007*\"size\"'),\n",
       " (3,\n",
       "  '0.020*\"model\" + 0.015*\"temperature\" + 0.011*\"clusters\" + 0.011*\"line\" + 0.010*\"case\" + 0.009*\"heating\" + 0.008*\"coherent\" + 0.008*\"atmosphere\" + 0.008*\"profile\" + 0.008*\"region\"'),\n",
       " (4,\n",
       "  '0.030*\"cell\" + 0.007*\"human\" + 0.007*\"level\" + 0.007*\"patient\" + 0.007*\"culture\" + 0.007*\"gene\" + 0.007*\"sediment\" + 0.007*\"expression\" + 0.006*\"sample\" + 0.006*\"day\"'),\n",
       " (5,\n",
       "  '0.017*\"node\" + 0.016*\"state\" + 0.015*\"algorithm\" + 0.013*\"time\" + 0.010*\"network\" + 0.009*\"module\" + 0.008*\"model\" + 0.008*\"system\" + 0.007*\"memory\" + 0.007*\"flow\"'),\n",
       " (6,\n",
       "  '0.024*\"soil\" + 0.017*\"electron\" + 0.011*\"energy\" + 0.008*\"field\" + 0.008*\"model\" + 0.007*\"flux\" + 0.006*\"ion\" + 0.006*\"observed\" + 0.006*\"rate\" + 0.006*\"change\"'),\n",
       " (7,\n",
       "  '0.021*\"flow\" + 0.015*\"wind\" + 0.014*\"model\" + 0.012*\"velocity\" + 0.012*\"speed\" + 0.012*\"power\" + 0.011*\"surface\" + 0.010*\"wave\" + 0.008*\"case\" + 0.008*\"vertical\"'),\n",
       " (8,\n",
       "  '0.023*\"let\" + 0.019*\"set\" + 0.014*\"theorem\" + 0.012*\"lemma\" + 0.011*\"element\" + 0.011*\"proof\" + 0.011*\"function\" + 0.011*\"case\" + 0.010*\"since\" + 0.010*\"group\"'),\n",
       " (9,\n",
       "  '0.018*\"plant\" + 0.015*\"gene\" + 0.014*\"soil\" + 0.009*\"level\" + 0.008*\"wind\" + 0.008*\"site\" + 0.008*\"system\" + 0.008*\"species\" + 0.007*\"factor\" + 0.007*\"year\"')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune alpha and beta\n",
    "# no similar package in python to perform cv on lda in gensim\n",
    "lda = models.LdaModel(corpus=corpus_gen, id2word=id2word, alpha='auto', eta='auto', num_topics=10, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.026*\"state\" + 0.019*\"node\" + 0.015*\"algorithm\" + 0.015*\"time\" + 0.013*\"model\" + 0.013*\"module\" + 0.013*\"memory\" + 0.011*\"system\" + 0.010*\"machine\" + 0.008*\"will\"'),\n",
       " (1,\n",
       "  '0.039*\"cell\" + 0.017*\"gene\" + 0.011*\"expression\" + 0.009*\"culture\" + 0.009*\"human\" + 0.008*\"patient\" + 0.007*\"plant\" + 0.007*\"level\" + 0.006*\"protein\" + 0.006*\"line\"'),\n",
       " (2,\n",
       "  '0.010*\"value\" + 0.009*\"time\" + 0.009*\"cost\" + 0.009*\"resource\" + 0.008*\"model\" + 0.008*\"flow\" + 0.008*\"equation\" + 0.008*\"network\" + 0.007*\"algorithm\" + 0.007*\"node\"'),\n",
       " (3,\n",
       "  '0.012*\"sediment\" + 0.010*\"site\" + 0.009*\"concentration\" + 0.009*\"value\" + 0.008*\"change\" + 0.007*\"core\" + 0.007*\"sea\" + 0.007*\"element\" + 0.006*\"section\" + 0.006*\"sample\"'),\n",
       " (4,\n",
       "  '0.032*\"soil\" + 0.010*\"feature\" + 0.008*\"network\" + 0.008*\"image\" + 0.008*\"species\" + 0.007*\"root\" + 0.007*\"plant\" + 0.007*\"treatment\" + 0.006*\"system\" + 0.006*\"level\"'),\n",
       " (5,\n",
       "  '0.031*\"electron\" + 0.019*\"energy\" + 0.013*\"ion\" + 0.010*\"surface\" + 0.009*\"layer\" + 0.009*\"signature\" + 0.009*\"measurement\" + 0.008*\"distribution\" + 0.008*\"field\" + 0.007*\"film\"'),\n",
       " (6,\n",
       "  '0.017*\"model\" + 0.012*\"flow\" + 0.011*\"temperature\" + 0.008*\"case\" + 0.007*\"velocity\" + 0.007*\"region\" + 0.007*\"field\" + 0.007*\"profile\" + 0.007*\"line\" + 0.007*\"atmosphere\"'),\n",
       " (7,\n",
       "  '0.023*\"particle\" + 0.011*\"material\" + 0.010*\"temperature\" + 0.010*\"ratio\" + 0.009*\"value\" + 0.007*\"sample\" + 0.007*\"wind\" + 0.007*\"model\" + 0.007*\"surface\" + 0.006*\"size\"'),\n",
       " (8,\n",
       "  '0.023*\"let\" + 0.023*\"set\" + 0.014*\"theorem\" + 0.012*\"lemma\" + 0.012*\"function\" + 0.011*\"element\" + 0.011*\"case\" + 0.011*\"since\" + 0.011*\"proof\" + 0.011*\"group\"'),\n",
       " (9,\n",
       "  '0.025*\"flow\" + 0.019*\"wind\" + 0.015*\"speed\" + 0.010*\"power\" + 0.009*\"approach\" + 0.008*\"control\" + 0.008*\"set\" + 0.007*\"risk\" + 0.007*\"technique\" + 0.007*\"normal\"')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus=corpus_gen, id2word=id2word, alpha='asymmetric', eta='auto', num_topics=10, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting function\n",
    "def compute_coherence_values(corpus, id2word, a, b):\n",
    "    \n",
    "    lda_model = LdaMulticore(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=a,\n",
    "                                           eta=b,\n",
    "                                           per_word_topics=True)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, corpus=corpus, dictionary=id2word, coherence='u_mass')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8331870384097492\n"
     ]
    }
   ],
   "source": [
    "print(compute_coherence_values(corpus=corpus_gen, id2word=id2word, a=0.01, b=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8297662915408827\n"
     ]
    }
   ],
   "source": [
    "print(compute_coherence_values(corpus=corpus_gen, id2word=id2word, a=0.1, b=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9133419300680116\n"
     ]
    }
   ],
   "source": [
    "print(compute_coherence_values(corpus=corpus_gen, id2word=id2word, a=0.3, b=0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8982664297476737\n"
     ]
    }
   ],
   "source": [
    "print(compute_coherence_values(corpus=corpus_gen, id2word=id2word, a=0.5, b=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8995639178131924\n"
     ]
    }
   ],
   "source": [
    "print(compute_coherence_values(corpus=corpus_gen, id2word=id2word, a=0.7, b=0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8990662658247104\n"
     ]
    }
   ],
   "source": [
    "print(compute_coherence_values(corpus=corpus_gen, id2word=id2word, a=1, b=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be frank, I don't think the class has prepared us for this question. I have to educate myself on the previous few questions, but I have no clue how to do this one in Python. I think even if I could use a package to jump to the conclusion in R, I wouldn't know what that meant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
